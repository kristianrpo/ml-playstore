{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# 1. Configuración de entorno\n",
    "\n",
    "En esta sección validamos que nuestro entorno de trabajo esté correctamente configurado antes de comenzar el análisis.  \n",
    "Los pasos incluyen:\n",
    "\n",
    "1. **Versión de Python**  \n",
    "   - Se verifica que esté instalada la versión **3.11 o superior** (se recomienda 3.13).  \n",
    "   - Esto garantiza compatibilidad con librerías modernas de análisis de datos y machine learning.\n",
    "\n",
    "2. **Importación de librerías base**  \n",
    "   - Se cargan librerías fundamentales:  \n",
    "     - `numpy`, `pandas`: manipulación y análisis de datos.  \n",
    "     - `matplotlib`, `seaborn`: visualización de datos.  \n",
    "     - `scipy`: funciones estadísticas.  \n",
    "   - Además se configuran estilos gráficos y opciones de visualización en pandas para trabajar con tablas más grandes.\n",
    "\n",
    "3. **Verificación de versiones críticas**  \n",
    "   - Se comprueba que `scikit-learn` esté instalado y en una versión **>= 1.0.1**.  \n",
    "   - Esto es esencial ya que `scikit-learn` se usará para el modelado (baseline y posteriores).\n",
    "\n",
    "Con esta configuración inicial aseguramos que el entorno sea reproducible y que todas las dependencias necesarias estén listas antes de continuar con el **EDA** y el **baseline**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "assert sys.version_info >= (3, 11), \"Este notebook trabajo con python 3.11 o superiores (recomendado 3.13)\"\n",
    "\n",
    "print(f\"Python {sys.version_info.major}.{sys.version_info.minor} instalado correctamente\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from scipy import stats\n",
    "\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "plt.rcParams['font.size'] = 12\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.float_format', '{:.2f}'.format)\n",
    "\n",
    "print(\"Librerías importadas exitosamente\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar versiones de librerías críticas\n",
    "from packaging import version\n",
    "import sklearn\n",
    "\n",
    "assert version.parse(sklearn.__version__) >= version.parse(\"1.0.1\"), \"Requiere scikit-learn >= 1.0.1\"\n",
    "print(f\"scikit-learn {sklearn.__version__} instalado\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "# 2. Metodología CRISP-DM\n",
    "## 2.1. Comprensión del Negocio\n",
    "El problema de Google Play Store  \n",
    "\n",
    "**Contexto:**  \n",
    "Es 2025. El mercado de aplicaciones móviles es altamente competitivo: millones de apps conviven en Google Play Store.  \n",
    "Los desarrolladores buscan mejorar la visibilidad de sus aplicaciones y los usuarios dependen del **rating promedio** para decidir qué descargar.  \n",
    "\n",
    "**Problema actual:**  \n",
    "- El rating se conoce **solo después** de que los usuarios descargan y reseñan.  \n",
    "- Las valoraciones son **altamente variables** y pueden depender de múltiples factores (categoría, descargas, precio, tamaño, tipo de app).  \n",
    "- Los desarrolladores carecen de una herramienta para **estimar la calificación potencial** de una app antes o durante su lanzamiento.  \n",
    "- La competencia es muy alta: una diferencia de décimas en rating puede significar miles de descargas menos.  \n",
    "\n",
    "---\n",
    "\n",
    "### 2.1.1. Solución propuesta  \n",
    "Construir un **sistema automático de predicción de rating** de apps a partir de sus características disponibles en el dataset de Google Play Store.  \n",
    "\n",
    "---\n",
    "\n",
    "### 2.1.2. Definiendo el éxito  \n",
    "\n",
    "**Métrica de negocio:**  \n",
    "- Ayudar a los desarrolladores a anticipar la valoración probable de su app.  \n",
    "- Reducir la dependencia de pruebas de mercado costosas o lentas.  \n",
    "- Identificar características clave que favorecen una alta valoración (≥ 4.3).  \n",
    "\n",
    "**Métrica técnica:**  \n",
    "- Lograr un **Error Absoluto Medio (MAE) < 0.5 estrellas** en la predicción de rating.  \n",
    "- Para la versión de clasificación (alta vs. baja calificación): obtener un **F1-score > 0.70**.  \n",
    "\n",
    "**¿Por qué estos valores?**  \n",
    "- El rating va de 1 a 5 → un error de 0.5 equivale a 10% de la escala.  \n",
    "- Una diferencia de medio punto puede marcar la visibilidad de la app en el ranking.  \n",
    "- Tasadores humanos (usuarios) también muestran variabilidad similar en sus calificaciones.  \n",
    "\n",
    "---\n",
    "\n",
    "### 2.1.3 Preguntas críticas antes de empezar  \n",
    "\n",
    "1. **¿Realmente necesitamos ML?**  \n",
    "   - Alternativa 1: Calcular el promedio de ratings por categoría → demasiado simple, no captura variabilidad.  \n",
    "   - Alternativa 2: Reglas heurísticas (ej. “si es gratis y tiene muchas descargas, tendrá rating alto”) → insuficiente.  \n",
    "   - **Conclusión:** Sí, ML es apropiado para capturar relaciones no lineales y múltiples factores.  \n",
    "\n",
    "2. **¿Qué pasa si el modelo falla?**  \n",
    "   - Transparencia: aclarar que es una estimación automática.  \n",
    "   - Complementar con rangos de predicción (ej: intervalo de confianza).  \n",
    "   - Mantener como referencia comparativa, no como único criterio de éxito.  \n",
    "\n",
    "3. **¿Cómo mediremos el impacto?**  \n",
    "   - Capacidad de anticipar apps con alta probabilidad de éxito.  \n",
    "   - Ahorro de tiempo en validaciones preliminares.  \n",
    "   - Insights para desarrolladores sobre qué factores influyen más en el rating.  \n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "## 2.2. Comprensión de los Datos  \n",
    "\n",
    "El objetivo de esta fase es explorar y entender el dataset de Google Play Store antes de construir modelos **(análisis exploratorio)**.  \n",
    "Nos centraremos en:  \n",
    "\n",
    "1. **Vista rápida del dataset**  \n",
    "   - Identificar dimensiones (filas × columnas).  \n",
    "   - Tipos de datos (numéricos, categóricos, texto, fechas).  \n",
    "   - Valores faltantes obvios y rangos sospechosos.\n",
    "\n",
    "2. **Descripción de variables**  \n",
    "   - Revisar cada columna y entender su significado.  \n",
    "   - Detectar qué variables podrían ser útiles como predictores y cuál será la variable objetivo (rating).  \n",
    "\n",
    "3. **Detección de problemas en los datos**  \n",
    "   - Análisis de valores faltantes.  \n",
    "   - Estrategias: eliminar filas/columnas, imputar valores o crear indicadores de “dato faltante”.  \n",
    "\n",
    "4. **Estadísticas descriptivas y univariadas**  \n",
    "   - Media vs mediana (sesgo de la distribución).  \n",
    "   - Desviación estándar (variabilidad, posibles outliers).  \n",
    "   - Mínimos/máximos sospechosos.  \n",
    "   - Histogramas para ver forma (normal, sesgada, bimodal, uniforme, picos extraños).  \n",
    "\n",
    "5. **Análisis de variables categóricas**  \n",
    "   - Distribución de categorías (ej. categorías de apps, tipo de app, content rating).  \n",
    "   - Detección de clases dominantes o categorías poco representadas.  \n",
    "\n",
    "6. **Correlaciones y relaciones entre variables**  \n",
    "   - Matriz de correlación de Pearson para variables numéricas.  \n",
    "   - Identificar relaciones fuertes, moderadas o débiles.  \n",
    "   - Importante: recordar que **correlación ≠ causalidad**.  \n",
    "\n",
    "---\n",
    "\n",
    "**Nota:**  \n",
    "No siempre es necesario aplicar todos los pasos con igual profundidad.  \n",
    "- Para este proyecto, el foco está en **identificar variables relevantes para predecir el rating** y **limpiar datos inconsistentes**.  \n",
    "- Otros análisis más complejos (ej. NLP sobre descripciones) se pueden dejar como trabajo futuro (según trabajos de referencia investigados).\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "### 2.2.1 Descarga de datos  \n",
    "\n",
    "En este paso descargamos el dataset de Google Play Store desde Kaggle y lo organizamos en la estructura de carpetas del proyecto.  \n",
    "\n",
    "1. Usamos la librería `kagglehub` para acceder al dataset público **`lava18/google-play-store-apps`** directamente desde Kaggle.  \n",
    "2. Se define una ruta clara dentro del proyecto para almacenar los datos originales: `../data/original/google-play-store/`. Esto ayuda a mantener la reproducibilidad y una estructura organizada.  \n",
    "3. Con la función `shutil.copytree` copiamos los archivos descargados a la carpeta destino. De esta forma, el dataset queda disponible en nuestro directorio de trabajo para su análisis posterior.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "import shutil\n",
    "\n",
    "def download_data(origin_repository, target_folder):\n",
    "    # Descargar dataset\n",
    "    path = kagglehub.dataset_download(origin_repository)\n",
    "    \n",
    "    # Copiar los archivos descargados\n",
    "    shutil.copytree(path, target_folder, dirs_exist_ok=True)\n",
    "    \n",
    "    print(\"Dataset guardado:\", destino)\n",
    "\n",
    "download_data(\"lava18/google-play-store-apps\", \"../data/original/google-play-store\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "### 2.2.2 Carga de datos  \n",
    "\n",
    "En este paso realizamos la **lectura del archivo CSV** que contiene el dataset descargado previamente.  \n",
    "\n",
    "- Definimos una función `load_data(path, file)` que recibe la ruta y el nombre del archivo, y lo carga con `pandas.read_csv()`.  \n",
    "- Cargamos el dataset principal en la variable `applications_data` desde la carpeta `../data/original/google-play-store/`.  \n",
    "- Incluimos una verificación simple:  \n",
    "  - Si el dataset se carga con éxito, se imprime `\"Dataset loaded\"`.  \n",
    "  - En caso contrario, se muestra un mensaje de error.  \n",
    "\n",
    "Con esta validación aseguramos que el archivo esté disponible y correctamente leído antes de continuar con el análisis exploratorio.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def load_data(path, file):\n",
    "    return pd.read_csv(f\"{path}/{file}\")\n",
    "\n",
    "def convert_numeric_columns(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Convierte a numéricas solo las columnas que deberían serlo, sin tocar 'Size'.\n",
    "    Usa to_numeric(errors='coerce') para evitar ValueError si aparece texto.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "\n",
    "    # Rating\n",
    "    if \"Rating\" in df.columns:\n",
    "        df[\"Rating\"] = pd.to_numeric(df[\"Rating\"], errors=\"coerce\")\n",
    "\n",
    "    # Reviews: quitar comas y cualquier carácter no numérico/punto\n",
    "    if \"Reviews\" in df.columns:\n",
    "        df[\"Reviews\"] = (\n",
    "            df[\"Reviews\"].astype(str)\n",
    "            .str.replace(r\"[^\\d.]\", \"\", regex=True)\n",
    "            .pipe(pd.to_numeric, errors=\"coerce\")\n",
    "        )\n",
    "\n",
    "    # Installs: quitar +, comas y cualquier carácter no numérico/punto\n",
    "    if \"Installs\" in df.columns:\n",
    "        df[\"Installs Numeric\"] = (\n",
    "            df[\"Installs\"].astype(str)\n",
    "            .str.replace(r\"[^\\d.]\", \"\", regex=True)\n",
    "            .pipe(pd.to_numeric, errors=\"coerce\")\n",
    "        )\n",
    "\n",
    "    # Price: quitar $ y cualquier carácter no numérico/punto\n",
    "    if \"Price\" in df.columns:\n",
    "        df[\"Price\"] = (\n",
    "            df[\"Price\"].astype(str)\n",
    "            .str.replace(r\"[^\\d.]\", \"\", regex=True)\n",
    "            .pipe(pd.to_numeric, errors=\"coerce\")\n",
    "        )\n",
    "\n",
    "\n",
    "    if \"Size\" in df.columns:\n",
    "        def parse_size(x):\n",
    "            if isinstance(x, str):\n",
    "                x = x.strip()\n",
    "                if x.endswith(\"M\"):\n",
    "                    return float(x[:-1])\n",
    "                elif x.endswith(\"k\") or x.endswith(\"K\"):\n",
    "                    return float(x[:-1]) / 1024  # KB -> MB\n",
    "                else:\n",
    "                    return np.nan\n",
    "            return np.nan\n",
    "        df[\"Size\"] = df[\"Size\"].apply(parse_size)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "temp_applications_data = load_data(\"../data/original/google-play-store\", \"googleplaystore.csv\")\n",
    "applications_data = convert_numeric_columns(temp_applications_data)\n",
    "\n",
    "\n",
    "if len(applications_data):\n",
    "    print(\"Dataset cargado\")\n",
    "else:\n",
    "    print(\"Error cargando dataset\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "### 2.2.3 Vista rápida del dataset\n",
    "\n",
    "**Dimensiones y columnas**\n",
    "- Registros: **10,841** filas.\n",
    "- Columnas: actualmente **14**; **originalmente eran 13** y se **añadió** una columna derivada: **`Installs Numeric`** para análisis con describe.\n",
    "- Memoria aproximada: **~1.2 MB**.\n",
    "\n",
    "**Tipos de datos (y transformaciones realizadas)**\n",
    "- Numéricas (`float64`): `Rating`, `Reviews`, `Size`, `Price`, **`Installs Numeric`**.\n",
    "- Categóricas / texto (`object`): `App`, `Category`, `Installs` *(forma original con “1,000+”)*, `Type`, `Content Rating`, `Genres`, `Last Updated`, `Current Ver`, `Android Ver`.\n",
    "- Transformaciones ya aplicadas:\n",
    "  - **`Installs`** se **conservó** en su formato original (categórico con “+” y comas) **y** se creó **`Installs Numeric`** mapeando esos rangos a números (0 … 1,000,000,000).\n",
    "  - **`Price`**, **`Reviews`** y **`Size`** fueron normalizadas/parseadas a **numérico** para análisis y modelado.\n",
    "\n",
    "**Valores faltantes (no-null count → faltantes aprox.)**\n",
    "- `Rating`: 9,367 → **1,474 faltantes (~13.6%)**.\n",
    "- `Size`: 9,145 → **1,696 faltantes (~15.6%)**.\n",
    "- `Current Ver`: 10,833 → **8 faltantes (~0.07%)**.\n",
    "- `Android Ver`: 10,838 → **3 faltantes (~0.03%)**.\n",
    "- `Content Rating`: 10,840 → **1 faltante (~0.01%)**.\n",
    "- `Price`: 10,840 → **1 faltante (~0.01%)**.\n",
    "- `Installs Numeric`: 10,840 → **1 faltante (~0.01%)**.\n",
    "- Resto de columnas: **sin faltantes**.\n",
    "\n",
    "**Duplicados:**\n",
    "-   Se identificaron **483 filas duplicadas** (≈ **4.46%** del\n",
    "    dataset).\\\n",
    "-   Ejemplos de duplicados incluyen apps como:\n",
    "    -   *Quick PDF Scanner + OCR FREE*\\\n",
    "    -   *Box*\\\n",
    "    -   *Google My Business*\\\n",
    "    -   *ZOOM Cloud Meetings*\\\n",
    "    -   *join.me -- Simple Meetings*\\\n",
    "\n",
    "**Rangos y valores sospechosos (según `describe()`)**\n",
    "- `Rating`: **min = 1.0**, **max = 19.0** → **19** es inválido para la escala 1–5 (error de dato a corregir).\n",
    "- `Reviews`: media ~ **444k**, **p75 ≈ 54,768**, **max ≈ 78M** → valores altos plausibles; tratar como **outliers**.\n",
    "- `Size` (MB): media ~ **21.5**, **p50 = 13**, **p75 = 30**, **max = 100** → distribución sesgada a la derecha; mínimos muy bajos (**0.01**) a revisar.\n",
    "- `Price` (USD): **mediana = 0** y **p75 = 0** → la mayoría son **apps gratuitas**; **max = 400** sugiere outliers de precio.\n",
    "- `Installs Numeric`: **p25 = 1,000**, **p50 = 100,000**, **p75 = 5,000,000**, **max = 1,000,000,000** → escala muy amplia; conviene usar **transformaciones log** o **binning** en el EDA/modelado.\n",
    "\n",
    "**Conclusión inicial**\n",
    "- Los **faltantes** más relevantes están en `Rating` y `Size`; habrá que decidir estategía para aumentar, imputar o nivelar los datos.\n",
    "- Existen **outliers (no legítimos)** (ej. `Rating = 19`) y variables con **colas largas** (ej. `Reviews`, `Installs Numeric`, `Price`).\n",
    "- Eliminar **duplicados** para evitar sesgos de análisis y que no introduzcan ruidos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"INFORMACIÓN GENERAL DEL DATASET\".center(80))\n",
    "print(\"=\" * 80)\n",
    "\n",
    "display(applications_data.head().style.background_gradient(cmap='RdYlGn', subset=['Rating']))\n",
    "\n",
    "# Información detallada\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"ESTRUCTURA DE DATOS\".center(80))\n",
    "print(\"=\" * 80)\n",
    "applications_data.info()\n",
    "\n",
    "# Estadísticas descriptivas\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"ESTADÍSTICAS DESCRIPTIVAS\".center(80))\n",
    "print(\"=\" * 80)\n",
    "display(applications_data.describe().round(2).T)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"DATOS DUPLICADOS\".center(80))\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Contar duplicados\n",
    "num_duplicados = applications_data.duplicated().sum()\n",
    "print(f\"Total de registros duplicados: {num_duplicados}\")\n",
    "\n",
    "# Mostrar ejemplos de duplicados si existen\n",
    "if num_duplicados > 0:\n",
    "    print(\"\\nEjemplos de filas duplicadas:\\n\")\n",
    "    display(applications_data[applications_data.duplicated()].head())\n",
    "else:\n",
    "    print(\"No se encontraron registros duplicados.\")\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"INFORMACIÓN GENERAL DEL DATASET\".center(80))\n",
    "print(\"=\" * 80)\n",
    "\n",
    "display(applications_data.head().style.background_gradient(cmap='RdYlGn', subset=['Rating']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (ml-playstore)",
   "language": "python",
   "name": "ml-playstore"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
