{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# 1. Configuración de entorno\n",
    "\n",
    "En esta sección validamos que nuestro entorno de trabajo esté correctamente configurado antes de comenzar el análisis.  \n",
    "Los pasos incluyen:\n",
    "\n",
    "1. **Versión de Python**  \n",
    "   - Se verifica que esté instalada la versión **3.11 o superior** (se recomienda 3.13).  \n",
    "   - Esto garantiza compatibilidad con librerías modernas de análisis de datos y machine learning.\n",
    "\n",
    "2. **Importación de librerías base**  \n",
    "   - Se cargan librerías fundamentales:  \n",
    "     - `numpy`, `pandas`: manipulación y análisis de datos.  \n",
    "     - `matplotlib`, `seaborn`: visualización de datos.  \n",
    "     - `scipy`: funciones estadísticas.  \n",
    "   - Además se configuran estilos gráficos y opciones de visualización en pandas para trabajar con tablas más grandes.\n",
    "\n",
    "3. **Verificación de versiones críticas**  \n",
    "   - Se comprueba que `scikit-learn` esté instalado y en una versión **>= 1.0.1**.  \n",
    "   - Esto es esencial ya que `scikit-learn` se usará para el modelado (baseline y posteriores).\n",
    "\n",
    "Con esta configuración inicial aseguramos que el entorno sea reproducible y que todas las dependencias necesarias estén listas antes de continuar con el **EDA** y el **baseline**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "assert sys.version_info >= (3, 11), \"Este notebook trabajo con python 3.11 o superiores (recomendado 3.13)\"\n",
    "\n",
    "print(f\"Python {sys.version_info.major}.{sys.version_info.minor} instalado correctamente\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from scipy import stats\n",
    "\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "plt.rcParams['font.size'] = 12\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.float_format', '{:.2f}'.format)\n",
    "\n",
    "print(\"Librerías importadas exitosamente\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar versiones de librerías críticas\n",
    "from packaging import version\n",
    "import sklearn\n",
    "\n",
    "assert version.parse(sklearn.__version__) >= version.parse(\"1.0.1\"), \"Requiere scikit-learn >= 1.0.1\"\n",
    "print(f\"scikit-learn {sklearn.__version__} instalado\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "# 2. Metodología CRISP-DM\n",
    "## 2.1. Comprensión del Negocio\n",
    "El problema de Google Play Store  \n",
    "\n",
    "**Contexto:**  \n",
    "Es 2025. El mercado de aplicaciones móviles es altamente competitivo: millones de apps conviven en Google Play Store.  \n",
    "Los desarrolladores buscan mejorar la visibilidad de sus aplicaciones y los usuarios dependen del **rating promedio** para decidir qué descargar.  \n",
    "\n",
    "**Problema actual:**  \n",
    "- El rating se conoce **solo después** de que los usuarios descargan y reseñan.  \n",
    "- Las valoraciones son **altamente variables** y pueden depender de múltiples factores (categoría, descargas, precio, tamaño, tipo de app).  \n",
    "- Los desarrolladores carecen de una herramienta para **estimar la calificación potencial** de una app antes o durante su lanzamiento.  \n",
    "- La competencia es muy alta: una diferencia de décimas en rating puede significar miles de descargas menos.  \n",
    "\n",
    "---\n",
    "\n",
    "### 2.1.1. Solución propuesta  \n",
    "Construir un **sistema automático de predicción de rating** de apps a partir de sus características disponibles en el dataset de Google Play Store.  \n",
    "\n",
    "---\n",
    "\n",
    "### 2.1.2. Definiendo el éxito  \n",
    "\n",
    "**Métrica de negocio:**  \n",
    "- Ayudar a los desarrolladores a anticipar la valoración probable de su app.  \n",
    "- Reducir la dependencia de pruebas de mercado costosas o lentas.  \n",
    "- Identificar características clave que favorecen una alta valoración (≥ 4.3).  \n",
    "\n",
    "**Métrica técnica:**  \n",
    "- Lograr un **Error Absoluto Medio (MAE) < 0.5 estrellas** en la predicción de rating.  \n",
    "- Para la versión de clasificación (alta vs. baja calificación): obtener un **F1-score > 0.70**.  \n",
    "\n",
    "**¿Por qué estos valores?**  \n",
    "- El rating va de 1 a 5 → un error de 0.5 equivale a 10% de la escala.  \n",
    "- Una diferencia de medio punto puede marcar la visibilidad de la app en el ranking.  \n",
    "- Tasadores humanos (usuarios) también muestran variabilidad similar en sus calificaciones.  \n",
    "\n",
    "---\n",
    "\n",
    "### 2.1.3 Preguntas críticas antes de empezar  \n",
    "\n",
    "1. **¿Realmente necesitamos ML?**  \n",
    "   - Alternativa 1: Calcular el promedio de ratings por categoría → demasiado simple, no captura variabilidad.  \n",
    "   - Alternativa 2: Reglas heurísticas (ej. “si es gratis y tiene muchas descargas, tendrá rating alto”) → insuficiente.  \n",
    "   - **Conclusión:** Sí, ML es apropiado para capturar relaciones no lineales y múltiples factores.  \n",
    "\n",
    "2. **¿Qué pasa si el modelo falla?**  \n",
    "   - Transparencia: aclarar que es una estimación automática.  \n",
    "   - Complementar con rangos de predicción (ej: intervalo de confianza).  \n",
    "   - Mantener como referencia comparativa, no como único criterio de éxito.  \n",
    "\n",
    "3. **¿Cómo mediremos el impacto?**  \n",
    "   - Capacidad de anticipar apps con alta probabilidad de éxito.  \n",
    "   - Ahorro de tiempo en validaciones preliminares.  \n",
    "   - Insights para desarrolladores sobre qué factores influyen más en el rating.  \n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "## 2.2. Comprensión de los Datos  \n",
    "\n",
    "El objetivo de esta fase es explorar y entender el dataset de Google Play Store antes de construir modelos **(análisis exploratorio)**.  \n",
    "Nos centraremos en:  \n",
    "\n",
    "1. **Vista rápida del dataset**  \n",
    "   - Identificar dimensiones (filas × columnas).  \n",
    "   - Tipos de datos (numéricos, categóricos, texto, fechas).  \n",
    "   - Valores faltantes obvios y rangos sospechosos.\n",
    "\n",
    "2. **Descripción de variables**  \n",
    "   - Revisar cada columna y entender su significado.  \n",
    "   - Detectar qué variables podrían ser útiles como predictores y cuál será la variable objetivo (rating).  \n",
    "\n",
    "3. **Detección de problemas en los datos**  \n",
    "   - Análisis de valores faltantes.  \n",
    "   - Estrategias: eliminar filas/columnas, imputar valores o crear indicadores de “dato faltante”.  \n",
    "\n",
    "4. **Estadísticas descriptivas y univariadas**  \n",
    "   - Media vs mediana (sesgo de la distribución).  \n",
    "   - Desviación estándar (variabilidad, posibles outliers).  \n",
    "   - Mínimos/máximos sospechosos.  \n",
    "   - Histogramas para ver forma (normal, sesgada, bimodal, uniforme, picos extraños).  \n",
    "\n",
    "5. **Análisis de variables categóricas**  \n",
    "   - Distribución de categorías (ej. categorías de apps, tipo de app, content rating).  \n",
    "   - Detección de clases dominantes o categorías poco representadas.  \n",
    "\n",
    "6. **Correlaciones y relaciones entre variables**  \n",
    "   - Matriz de correlación de Pearson para variables numéricas.  \n",
    "   - Identificar relaciones fuertes, moderadas o débiles.  \n",
    "   - Importante: recordar que **correlación ≠ causalidad**.  \n",
    "\n",
    "---\n",
    "\n",
    "**Nota:**  \n",
    "No siempre es necesario aplicar todos los pasos con igual profundidad.  \n",
    "- Para este proyecto, el foco está en **identificar variables relevantes para predecir el rating** y **limpiar datos inconsistentes**.  \n",
    "- Otros análisis más complejos (ej. NLP sobre descripciones) se pueden dejar como trabajo futuro (según trabajos de referencia investigados).\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "### 2.2.1 Descarga de datos  \n",
    "\n",
    "En este paso descargamos el dataset de Google Play Store desde Kaggle y lo organizamos en la estructura de carpetas del proyecto.  \n",
    "\n",
    "1. Usamos la librería `kagglehub` para acceder al dataset público **`lava18/google-play-store-apps`** directamente desde Kaggle.  \n",
    "2. Se define una ruta clara dentro del proyecto para almacenar los datos originales: `../data/original/google-play-store/`. Esto ayuda a mantener la reproducibilidad y una estructura organizada.  \n",
    "3. Con la función `shutil.copytree` copiamos los archivos descargados a la carpeta destino. De esta forma, el dataset queda disponible en nuestro directorio de trabajo para su análisis posterior.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kagglehub\n",
    "import shutil\n",
    "\n",
    "def download_data(origin_repository, target_folder):\n",
    "    # Descargar dataset\n",
    "    path = kagglehub.dataset_download(origin_repository)\n",
    "    \n",
    "    # Copiar los archivos descargados\n",
    "    shutil.copytree(path, target_folder, dirs_exist_ok=True)\n",
    "    \n",
    "    print(\"Dataset guardado:\", destino)\n",
    "\n",
    "download_data(\"lava18/google-play-store-apps\", \"../data/original/google-play-store\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "### 2.2.2 Carga de datos  \n",
    "\n",
    "En este paso realizamos la **lectura del archivo CSV** que contiene el dataset descargado previamente.  \n",
    "\n",
    "- Definimos una función `load_data(path, file)` que recibe la ruta y el nombre del archivo, y lo carga con `pandas.read_csv()`.  \n",
    "- Cargamos el dataset principal en la variable `applications_data` desde la carpeta `../data/original/google-play-store/`.  \n",
    "- Incluimos una verificación simple:  \n",
    "  - Si el dataset se carga con éxito, se imprime `\"Dataset loaded\"`.  \n",
    "  - En caso contrario, se muestra un mensaje de error.  \n",
    "\n",
    "Con esta validación aseguramos que el archivo esté disponible y correctamente leído antes de continuar con el análisis exploratorio.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def load_data(path, file):\n",
    "    return pd.read_csv(f\"{path}/{file}\")\n",
    "\n",
    "def convert_numeric_columns(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Convierte a numéricas solo las columnas que deberían serlo, sin tocar 'Size'.\n",
    "    Usa to_numeric(errors='coerce') para evitar ValueError si aparece texto.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "\n",
    "    # Rating\n",
    "    if \"Rating\" in df.columns:\n",
    "        df[\"Rating\"] = pd.to_numeric(df[\"Rating\"], errors=\"coerce\")\n",
    "\n",
    "    # Reviews: quitar comas y cualquier carácter no numérico/punto\n",
    "    if \"Reviews\" in df.columns:\n",
    "        df[\"Reviews\"] = (\n",
    "            df[\"Reviews\"].astype(str)\n",
    "            .str.replace(r\"[^\\d.]\", \"\", regex=True)\n",
    "            .pipe(pd.to_numeric, errors=\"coerce\")\n",
    "        )\n",
    "\n",
    "    # Installs: quitar +, comas y cualquier carácter no numérico/punto\n",
    "    if \"Installs\" in df.columns:\n",
    "        df[\"Installs Numeric\"] = (\n",
    "            df[\"Installs\"].astype(str)\n",
    "            .str.replace(r\"[^\\d.]\", \"\", regex=True)\n",
    "            .pipe(pd.to_numeric, errors=\"coerce\")\n",
    "        )\n",
    "\n",
    "    # Price: quitar $ y cualquier carácter no numérico/punto\n",
    "    if \"Price\" in df.columns:\n",
    "        df[\"Price\"] = (\n",
    "            df[\"Price\"].astype(str)\n",
    "            .str.replace(r\"[^\\d.]\", \"\", regex=True)\n",
    "            .pipe(pd.to_numeric, errors=\"coerce\")\n",
    "        )\n",
    "\n",
    "\n",
    "    if \"Size\" in df.columns:\n",
    "        def parse_size(x):\n",
    "            if isinstance(x, str):\n",
    "                x = x.strip()\n",
    "                if x.endswith(\"M\"):\n",
    "                    return float(x[:-1])\n",
    "                elif x.endswith(\"k\") or x.endswith(\"K\"):\n",
    "                    return float(x[:-1]) / 1024  # KB -> MB\n",
    "                else:\n",
    "                    return np.nan\n",
    "            return np.nan\n",
    "        df[\"Size\"] = df[\"Size\"].apply(parse_size)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "temp_applications_data = load_data(\"../data/original/google-play-store\", \"googleplaystore.csv\")\n",
    "applications_data = convert_numeric_columns(temp_applications_data)\n",
    "\n",
    "\n",
    "if len(applications_data):\n",
    "    print(\"Dataset cargado\")\n",
    "else:\n",
    "    print(\"Error cargando dataset\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "### 2.2.3 Vista rápida del dataset\n",
    "\n",
    "**Dimensiones y columnas**\n",
    "- Registros: **10,841** filas.\n",
    "- Columnas: actualmente **14**; **originalmente eran 13** y se **añadió** una columna derivada: **`Installs Numeric`** para análisis con describe.\n",
    "- Memoria aproximada: **~1.2 MB**.\n",
    "\n",
    "**Tipos de datos (y transformaciones realizadas)**\n",
    "- Numéricas (`float64`): `Rating`, `Reviews`, `Size`, `Price`, **`Installs Numeric`**.\n",
    "- Categóricas / texto (`object`): `App`, `Category`, `Installs` *(forma original con “1,000+”)*, `Type`, `Content Rating`, `Genres`, `Last Updated`, `Current Ver`, `Android Ver`.\n",
    "- Transformaciones ya aplicadas:\n",
    "  - **`Installs`** se **conservó** en su formato original (categórico con “+” y comas) **y** se creó **`Installs Numeric`** mapeando esos rangos a números (0 … 1,000,000,000).\n",
    "  - **`Price`**, **`Reviews`** y **`Size`** fueron normalizadas/parseadas a **numérico** para análisis y modelado.\n",
    "\n",
    "**Valores faltantes (no-null count → faltantes aprox.)**\n",
    "- `Rating`: 9,367 → **1,474 faltantes (~13.6%)**.\n",
    "- `Size`: 9,145 → **1,696 faltantes (~15.6%)**.\n",
    "- `Current Ver`: 10,833 → **8 faltantes (~0.07%)**.\n",
    "- `Android Ver`: 10,838 → **3 faltantes (~0.03%)**.\n",
    "- `Content Rating`: 10,840 → **1 faltante (~0.01%)**.\n",
    "- `Price`: 10,840 → **1 faltante (~0.01%)**.\n",
    "- `Installs Numeric`: 10,840 → **1 faltante (~0.01%)**.\n",
    "- Resto de columnas: **sin faltantes**.\n",
    "\n",
    "**Duplicados:**\n",
    "-   Se identificaron **483 filas duplicadas** (≈ **4.46%** del\n",
    "    dataset).\\\n",
    "-   Ejemplos de duplicados incluyen apps como:\n",
    "    -   *Quick PDF Scanner + OCR FREE*\\\n",
    "    -   *Box*\\\n",
    "    -   *Google My Business*\\\n",
    "    -   *ZOOM Cloud Meetings*\\\n",
    "    -   *join.me -- Simple Meetings*\\\n",
    "\n",
    "**Rangos y valores sospechosos (según `describe()`)**\n",
    "- `Rating`: **min = 1.0**, **max = 19.0** → **19** es inválido para la escala 1–5 (error de dato a corregir).\n",
    "- `Reviews`: media ~ **444k**, **p75 ≈ 54,768**, **max ≈ 78M** → valores altos plausibles; tratar como **outliers**.\n",
    "- `Size` (MB): media ~ **21.5**, **p50 = 13**, **p75 = 30**, **max = 100** → distribución sesgada a la derecha; mínimos muy bajos (**0.01**) a revisar.\n",
    "- `Price` (USD): **mediana = 0** y **p75 = 0** → la mayoría son **apps gratuitas**; **max = 400** sugiere outliers de precio.\n",
    "- `Installs Numeric`: **p25 = 1,000**, **p50 = 100,000**, **p75 = 5,000,000**, **max = 1,000,000,000** → escala muy amplia; conviene usar **transformaciones log** o **binning** en el EDA/modelado.\n",
    "\n",
    "**Conclusión inicial**\n",
    "- Los **faltantes** más relevantes están en `Rating` y `Size`; habrá que decidir estategía para aumentar, imputar o nivelar los datos.\n",
    "- Existen **outliers (no legítimos)** (ej. `Rating = 19`) y variables con **colas largas** (ej. `Reviews`, `Installs Numeric`, `Price`).\n",
    "- Eliminar **duplicados** para evitar sesgos de análisis y que no introduzcan ruidos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"INFORMACIÓN GENERAL DEL DATASET\".center(80))\n",
    "print(\"=\" * 80)\n",
    "\n",
    "display(applications_data.head().style.background_gradient(cmap='RdYlGn', subset=['Rating']))\n",
    "\n",
    "# Información detallada\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"ESTRUCTURA DE DATOS\".center(80))\n",
    "print(\"=\" * 80)\n",
    "applications_data.info()\n",
    "\n",
    "# Estadísticas descriptivas\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"ESTADÍSTICAS DESCRIPTIVAS\".center(80))\n",
    "print(\"=\" * 80)\n",
    "display(applications_data.describe().round(2).T)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"DATOS DUPLICADOS\".center(80))\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Contar duplicados\n",
    "num_duplicados = applications_data.duplicated().sum()\n",
    "print(f\"Total de registros duplicados: {num_duplicados}\")\n",
    "\n",
    "# Mostrar ejemplos de duplicados si existen\n",
    "if num_duplicados > 0:\n",
    "    print(\"\\nEjemplos de filas duplicadas:\\n\")\n",
    "    display(applications_data[applications_data.duplicated()].head())\n",
    "else:\n",
    "    print(\"No se encontraron registros duplicados.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "### 2.2.4 Descripción de las variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = [\n",
    "    'App', 'Category', 'Rating', 'Reviews', 'Size', 'Installs', 'Type', 'Price',\n",
    "    'Content Rating', 'Genres', 'Last Updated', 'Current Ver', 'Android Ver',\n",
    "    'Installs Numeric'\n",
    "]\n",
    "\n",
    "tipos = [\n",
    "    'Categórica',          # App\n",
    "    'Categórica',          # Category\n",
    "    'Numérica (Target)',   # Rating\n",
    "    'Numérica',            # Reviews\n",
    "    'Numérica (MB)',       # Size\n",
    "    'Categórica (rango)',  # Installs\n",
    "    'Categórica',          # Type\n",
    "    'Numérica (USD)',      # Price\n",
    "    'Categórica',          # Content Rating\n",
    "    'Categórica',          # Genres\n",
    "    'Texto (fecha)',       # Last Updated (parseable a fecha)\n",
    "    'Texto',               # Current Ver\n",
    "    'Texto',               # Android Ver\n",
    "    'Numérica'             # Installs Numeric\n",
    "]\n",
    "\n",
    "descripciones = [\n",
    "    'Nombre de la aplicación.',\n",
    "    'Categoría oficial de la app en Google Play.',\n",
    "    'Calificación promedio de usuarios (1 a 5).',\n",
    "    'Número de reseñas reportadas.',\n",
    "    'Tamaño aproximado de la app en MB.',\n",
    "    'Instalaciones en rango (p.ej., \"1,000+\").',\n",
    "    'Tipo de app (Free / Paid).',\n",
    "    'Precio en USD (0 para gratuitas).',\n",
    "    'Clasificación de contenido (Everyone, Teen, etc.).',\n",
    "    'Género(s) de la app.',\n",
    "    'Fecha de última actualización (texto en origen).',\n",
    "    'Versión actual declarada por el desarrollador.',\n",
    "    'Versión mínima de Android requerida.',\n",
    "    'Instalaciones convertidas a número para análisis.'\n",
    "]\n",
    "\n",
    "valores_faltantes = [applications_data[col].isnull().sum() if col in applications_data.columns else None for col in variables]\n",
    "\n",
    "metadata = {\n",
    "    'Variable': variables,\n",
    "    'Tipo': tipos,\n",
    "    'Descripción': descripciones,\n",
    "    'Valores Faltantes': valores_faltantes\n",
    "}\n",
    "\n",
    "df_metadata = pd.DataFrame(metadata)\n",
    "\n",
    "# Mostrar con resaltado de faltantes\n",
    "styled = df_metadata.style.applymap(\n",
    "    lambda x: 'background-color: #ffcccc' if isinstance(x, (int, float)) and x > 0 else '',\n",
    "    subset=['Valores Faltantes']\n",
    ")\n",
    "\n",
    "display(styled)\n",
    "\n",
    "# Resumen de dtypes originales (informativo)\n",
    "dtypes_resumen = applications_data[variables].dtypes.astype(str).reset_index()\n",
    "dtypes_resumen.columns = ['Variable', 'dtype pandas']\n",
    "display(dtypes_resumen)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "### 2.2.5 Detección de problemas en los datos "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "**Resumen de hallazgos (valores faltantes):**\n",
    "- `Size` ≈ 15.6% y `Rating` ≈ 13.6% concentran la mayoría de los faltantes.\n",
    "- Faltantes puntuales (≈0.01%): `Type`, `Price`, `Content Rating`, `Installs Numeric` ocurren en la misma(s) fila(s) → patrón conjunto.\n",
    "- `Android Ver` (0.03%) y `Current Ver` (0.07%) con faltantes residuales, parcialmente correlacionados con el grupo anterior.\n",
    "\n",
    "**Heatmap de correlación de patrones de faltantes (interpretación):**\n",
    "- Correlación 1.00 entre `Type`, `Price`, `Content Rating`, `Installs Numeric`: las ausencias co-ocurren en el/los mismos registros. Acciones coordinadas.\n",
    "- `Android Ver` muestra correlación moderada (~0.58) con ese grupo: algunas veces falta junto con ellos.\n",
    "- `Size`, `Rating`, `Current Ver` tienen patrones de faltantes independientes del grupo anterior (correlaciones cercanas a 0), lo que sugiere causas distintas.\n",
    "\n",
    "#### Posibles estrategias de corrección\n",
    "\n",
    "- Limpieza básica\n",
    "  - Eliminar duplicados (483 filas) para evitar sesgos.\n",
    "  - Validar y corregir outliers imposibles, p. ej., `Rating = 19` → convertir a NaN para tratarlo como faltante.\n",
    "\n",
    "- Imputación (conservadora y por grupos)\n",
    "  - `Rating` (target): para modelado, eliminar filas sin `Rating`; para EDA descriptivo, imputar mediana por `Category` solo para visualización.\n",
    "  - `Size`: imputar mediana por `Category × Type` y crear indicador `size_missing`.\n",
    "  - `Android Ver`, `Current Ver`: imputar moda por `Category` y crear indicadores `androidver_missing`, `currentver_missing`.\n",
    "  - Faltantes conjuntos (`Type`, `Price`, `Content Rating`, `Installs Numeric`):\n",
    "    - Si es 1 fila: eliminarla es lo más simple y seguro.\n",
    "    - Alternativa (si se prefiere imputar):\n",
    "      - `Type`: inferir desde `Price` (0 → Free, >0 → Paid).\n",
    "      - `Price`: 0 si `Type == Free`, si `Paid` usar mediana por `Category`.\n",
    "      - `Content Rating`: moda por `Category`.\n",
    "      - `Installs Numeric`: mediana por `Category × Type` o por bin de `Installs`.\n",
    "\n",
    "\n",
    "\n",
    "#### Estrategias de “nivelación” según los porcentajes observados\n",
    "\n",
    "- Size (~15.6% faltantes, >5% y <<60%)\n",
    "  - Acción: imputar mediana por grupo `Category × Type`.\n",
    "  - Añadir flag: `size_missing = 1` cuando falte (conserva señal de ausencia).\n",
    "  - Justificación: volumen relevante; la mediana por grupos respeta diferencias entre tipos/categorías.\n",
    "\n",
    "- Rating (~13.6% faltantes, >5% y <<60%) [variable objetivo]\n",
    "  - Para modelado: eliminar filas sin `Rating` (evita sesgo por imputación del target).\n",
    "  - Para EDA descriptivo: si se requiere visualizar completos, imputar mediana por `Category` solo para gráficos/tablas (no para entrenamiento).\n",
    "  - Justificación: imputar el target puede distorsionar métricas.\n",
    "\n",
    "- Current Ver (0.07%) y Android Ver (0.03%) (<5%)\n",
    "  - Acción: imputar con la moda por `Category`. Flags opcionales `currentver_missing` y `androidver_missing`.\n",
    "  - Justificación: impacto ínfimo; moda es suficiente y estable.\n",
    "\n",
    "- Faltantes “en bloque” en la misma fila: Type, Price, Content Rating, Installs Numeric (≈0.01% cada uno; correlación 1.00)\n",
    "  - Si es 1 fila: eliminarla directamente.\n",
    "  - Si hubiera más en el futuro y se prefiriera imputar coordinadamente:\n",
    "    - `Type` desde `Price` (0 → Free, >0 → Paid),\n",
    "    - `Price` = 0 si `Free`, si `Paid` usar mediana por `Category`,\n",
    "    - `Content Rating` = moda por `Category`,\n",
    "    - `Installs Numeric` = mediana por `Category × Type`.\n",
    "  - Justificación: co-ocurren; eliminar 1 fila no afecta el conjunto y evita inconsistencias.\n",
    "\n",
    "- Transformaciones para estabilizar distribuciones (complementarias a la imputación)\n",
    "  - `Reviews` y `Installs Numeric`: aplicar `log1p` para análisis y futuros modelos. *****************************\n",
    "  - `Installs` (rangos): tratar como ordinal/bins en el EDA.\n",
    "\n",
    "- Limpieza previa necesaria\n",
    "  - Eliminar duplicados (483 filas).\n",
    "  - Corregir valores imposibles detectados en el EDA (ej. `Rating = 19` → NaN) y re-entrar al flujo de imputación/nivelación anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_missing_values(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Análisis completo de valores faltantes con visualizaciones.\"\"\"\n",
    "    missing_counts = df.isnull().sum()\n",
    "    missing_pct = (missing_counts / len(df)) * 100\n",
    "\n",
    "    missing_df = pd.DataFrame({\n",
    "        'Columna': df.columns,\n",
    "        'Valores_Faltantes': missing_counts.values,\n",
    "        'Porcentaje': missing_pct.values,\n",
    "        'Tipo_Dato': df.dtypes.values\n",
    "    })\n",
    "\n",
    "    missing_df = missing_df[missing_df['Valores_Faltantes'] > 0].sort_values('Porcentaje', ascending=False)\n",
    "\n",
    "    if len(missing_df) == 0:\n",
    "        print(\"No hay valores faltantes en el dataset\")\n",
    "        return missing_df\n",
    "\n",
    "    # Visualización: barras y correlación de patrones de faltantes\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 5))\n",
    "\n",
    "    # Gráfico de barras de % faltantes\n",
    "    ax1.bar(missing_df['Columna'], missing_df['Porcentaje'], color='coral')\n",
    "    ax1.set_xlabel('Columna')\n",
    "    ax1.set_ylabel('Porcentaje de Valores Faltantes (%)')\n",
    "    ax1.set_title('Valores Faltantes por Columna')\n",
    "    ax1.axhline(y=5, color='r', linestyle='--', label='Umbral 5%')\n",
    "    ax1.axhline(y=60, color='purple', linestyle='--', label='Umbral 60%')\n",
    "    ax1.tick_params(axis='x', rotation=90)\n",
    "    ax1.legend()\n",
    "\n",
    "    # Heatmap de correlación de patrones de faltantes\n",
    "    mask_df = df[missing_df['Columna'].tolist()].isnull().astype(int)\n",
    "    if mask_df.shape[1] >= 2:\n",
    "        corr = mask_df.corr()\n",
    "        sns.heatmap(corr, annot=True, fmt='.2f', cmap='coolwarm', vmin=-1, vmax=1, ax=ax2)\n",
    "        ax2.set_title('Correlación de Patrones de Valores Faltantes')\n",
    "    else:\n",
    "        ax2.axis('off')\n",
    "        ax2.set_title('Correlación de faltantes (no aplica: 1 columna)')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    return missing_df\n",
    "\n",
    "missing_analysis = analyze_missing_values(applications_data)\n",
    "if missing_analysis is not None and not missing_analysis.empty:\n",
    "    display(missing_analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "### 2.2.6 Estadisticas descriptivas y univariadas (númerico)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "A partir de la tabla de estadísticas y los gráficos generados para `Rating`, `Reviews`, `Size`, `Price` e `Installs Numeric`, se observan los siguientes puntos clave.\n",
    "\n",
    "- Rating\n",
    "  - Media ≈ 4.19 y mediana ≈ 4.30 → ligera cola a la izquierda (más apps con rating alto). Hay un valor imposible (≈19), confirmado en el boxplot/Q-Q como outlier extremo.\n",
    "  - Outliers: ~5% por IQR, dominados por el valor inválido y algunos ratings bajos.\n",
    "  - Q-Q plot: desviación frente a normalidad, esperable para una variable acotada [1,5].\n",
    "  - Implicación/acción: eliminar filas sin `Rating` para modelado; corregir `Rating=19 → NaN` y excluir; no aplicar transformaciones (la escala es ya interpretables).\n",
    "\n",
    "- Reviews\n",
    "  - Media ≫ mediana (pico en 0–pocos miles; máximo ≈ 78M) → cola muy larga a la derecha.\n",
    "  - Boxplot: ~18% outliers por IQR (muchas apps con reseñas muy altas).\n",
    "  - Q-Q plot: gran desviación de normalidad (heavy tail).\n",
    "  - Relación con Rating: correlación positiva muy débil (~0.07), tendencia casi plana.\n",
    "  - Implicación/acción: usar `log1p(Reviews)` para estabilizar la distribución en análisis/modelado; considerar winsorizar p99.9 para vistas tabulares si se desea.\n",
    "\n",
    "- Size (MB)\n",
    "  - Media > mediana (≈ 21.5 vs 13) → sesgo a la derecha; valores hasta 100 MB.\n",
    "  - ~6% outliers por IQR, especialmente en colas altas.\n",
    "  - Q-Q plot: curvatura en colas; no normal.\n",
    "  - Relación con Rating: correlación positiva débil (~0.08); señal muy tenue.\n",
    "  - Implicación/acción: imputar faltantes por `Category × Type` y añadir `size_missing`; opcionalmente probar `log1p(Size)` o binning para robustecer.\n",
    "\n",
    "- Price (USD)\n",
    "  - Mediana = 0 (mayoría gratis) y cola a la derecha con máximos altos (≈ 400).\n",
    "  - ~7% outliers por IQR; Q-Q muestra heavy tail.\n",
    "  - Relación con Rating: correlación negativa muy débil (~-0.02).\n",
    "  - Implicación/acción: crear `is_free = (Price == 0)` y, si se usa `Price` continuo, considerar `log1p(Price)` para las pocas apps pagas; validar coherencia `Type=Free ⇒ Price=0`.\n",
    "\n",
    "- Installs Numeric\n",
    "  - Media ≫ mediana (100k) con máximo 1e9 → distribución extremadamente sesgada a la derecha.\n",
    "  - ~7–8% outliers por IQR; Q-Q muy alejado de normalidad.\n",
    "  - Relación con Rating: correlación débil positiva (~0.05) y tendencia casi plana.\n",
    "  - Implicación/acción: usar `log1p(Installs Numeric)` o bins ordinales para análisis; verificar coherencia con `Installs` textual.\n",
    "\n",
    "Recomendaciones transversales\n",
    "- Eliminar duplicados antes de resumir para evitar sesgos.\n",
    "- Tratar outliers evidentes no-legítimos (p. ej. `Rating=19`). Para colas largas legítimas (`Reviews`, `Installs Numeric`, `Price`): preferir `log1p` o winsorización solo para visualizaciones.\n",
    "- Mantener consistencia: `Type=Free ⇒ Price=0`; `Installs Numeric` coherente con el rango de `Installs`.\n",
    "- Para relaciones con `Rating`, las correlaciones lineales observadas son débiles; la señal puede emerger mejor con interacciones (p. ej., `is_free × installs_bin`) o modelos no lineales.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "# Selección de columnas numéricas relevantes\n",
    "numeric_cols = [c for c in ['Rating', 'Reviews', 'Size', 'Price', 'Installs Numeric'] if c in applications_data.columns]\n",
    "\n",
    "# Tabla de estadísticas básicas (media, mediana, std, min, p25, p50, p75, max)\n",
    "describe_tbl = applications_data[numeric_cols].describe(percentiles=[0.25, 0.5, 0.75]).T\n",
    "\n",
    "# Métricas adicionales robustas\n",
    "extra = pd.DataFrame(index=numeric_cols)\n",
    "extra['mad'] = [stats.median_abs_deviation(applications_data[c].dropna()) for c in numeric_cols]\n",
    "extra['skew'] = [applications_data[c].skew(skipna=True) for c in numeric_cols]\n",
    "extra['kurtosis'] = [applications_data[c].kurtosis(skipna=True) for c in numeric_cols]\n",
    "extra['cv'] = [applications_data[c].std(skipna=True) / applications_data[c].mean(skipna=True) if applications_data[c].mean(skipna=True) not in [0, np.nan] else np.nan for c in numeric_cols]\n",
    "\n",
    "stats_table = describe_tbl.join(extra)\n",
    "display(stats_table.round(3))\n",
    "\n",
    "\n",
    "def univariate_analysis(df: pd.DataFrame, column: str, target: str | None = None):\n",
    "    \"\"\"Análisis univariado con histograma, boxplot, Q-Q plot y relación con target.\"\"\"\n",
    "    series = df[column].dropna()\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "    # 1) Histograma con líneas de media y mediana\n",
    "    ax1 = axes[0, 0]\n",
    "    ax1.hist(series, bins=50, edgecolor='black', alpha=0.7)\n",
    "    ax1.axvline(series.mean(), color='red', linestyle='--', label=f\"Media: {series.mean():.2f}\")\n",
    "    ax1.axvline(series.median(), color='green', linestyle='--', label=f\"Mediana: {series.median():.2f}\")\n",
    "    ax1.set_title(f\"Distribución de {column}\")\n",
    "    ax1.set_xlabel(column)\n",
    "    ax1.set_ylabel('Frecuencia')\n",
    "    ax1.legend()\n",
    "    ax1.grid(alpha=0.3)\n",
    "\n",
    "    # 2) Boxplot + conteo de outliers (IQR)\n",
    "    ax2 = axes[0, 1]\n",
    "    bp = ax2.boxplot(series, vert=True, patch_artist=True)\n",
    "    bp['boxes'][0].set_facecolor('lightblue')\n",
    "    Q1, Q3 = series.quantile(0.25), series.quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    outliers_mask = (series < Q1 - 1.5 * IQR) | (series > Q3 + 1.5 * IQR)\n",
    "    n_out = int(outliers_mask.sum())\n",
    "    pct_out = 100 * n_out / len(series) if len(series) else 0\n",
    "    ax2.set_title(f\"Boxplot de {column}\")\n",
    "    ax2.set_ylabel(column)\n",
    "    ax2.grid(alpha=0.3)\n",
    "    ax2.text(1.1, Q3, f\"Outliers: {n_out} ({pct_out:.1f}%)\", fontsize=10)\n",
    "\n",
    "    # 3) Q-Q plot normal\n",
    "    ax3 = axes[1, 0]\n",
    "    stats.probplot(series, dist='norm', plot=ax3)\n",
    "    ax3.set_title('Q-Q Plot (Normalidad)')\n",
    "    ax3.grid(alpha=0.3)\n",
    "\n",
    "    # 4) Relación con target si aplica\n",
    "    ax4 = axes[1, 1]\n",
    "    if target is not None and target in df.columns and column != target:\n",
    "        valid = df[[column, target]].dropna()\n",
    "        ax4.scatter(valid[column], valid[target], alpha=0.4, s=10)\n",
    "        ax4.set_xlabel(column)\n",
    "        ax4.set_ylabel(target)\n",
    "        ax4.set_title(f\"{column} vs {target}\")\n",
    "        # Línea de tendencia (ajuste lineal simple)\n",
    "        if len(valid) > 1:\n",
    "            z = np.polyfit(valid[column], valid[target], 1)\n",
    "            p = np.poly1d(z)\n",
    "            xs = np.linspace(valid[column].min(), valid[column].max(), 200)\n",
    "            ax4.plot(xs, p(xs), 'r--', alpha=0.8, label='Tendencia')\n",
    "            corr = valid[column].corr(valid[target])\n",
    "            ax4.text(0.05, 0.95, f\"Correlación: {corr:.3f}\", transform=ax4.transAxes,\n",
    "                     fontsize=10, bbox=dict(boxstyle='round', facecolor='wheat'))\n",
    "            ax4.legend()\n",
    "    else:\n",
    "        ax4.axis('off')\n",
    "        ax4.grid(alpha=0.3)\n",
    "\n",
    "    plt.suptitle(f\"Análisis Univariado: {column}\", fontsize=14, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Ejecutar análisis univariado para cada métrica numérica, relacionando con Rating\n",
    "for col in numeric_cols:\n",
    "    univariate_analysis(applications_data, col, target='Rating')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "- Category\n",
    "  - Distribución: alta concentración en `FAMILY` (~19%) y `GAME` (~12%). El resto de categorías tienen menor peso individual; el grupo `Others` acumula ~31% del total.\n",
    "  - Rating por categoría: diferencias moderadas; la **mediana** suele estar entre 4.2–4.4. Algunas categorías muestran desviación estándar mayor (p. ej., `PRODUCTIVITY`, `LIFESTYLE`), indicando más variabilidad de valoración.\n",
    "  - Implicaciones: riesgo de sesgo por categorías mayoritarias en análisis agregados. Para modelado, conviene usar dummies Top-K o codificación ordinal/target encoding con cuidado (evitar fuga). Agrupar colas largas en `Others` es adecuado para visualización.\n",
    "\n",
    "- Content Rating\n",
    "  - Distribución: `Everyone` domina (~79%), seguido por `Teen` (~12%); `Mature 17+` y `Everyone 10+` suman ~9% en conjunto; clases raras casi nulas.\n",
    "  - Rating por nivel de contenido: medias similares (≈4.1–4.3). `Teen` tiende a mediana 4.3 y variabilidad algo menor; `Mature 17+` muestra algo más de dispersión.\n",
    "  - Implicaciones: por el fuerte desbalance, esta variable aporta señal limitada por sí sola. Útil como interacción con `Category`/`Genres`.\n",
    "\n",
    "- Type\n",
    "  - Distribución: `Free` ≈ 93%, `Paid` ≈ 7% (clase muy desbalanceada); existe un registro anómalo (valor 0) en los gráficos que debe eliminarse/corregirse.\n",
    "  - Rating por tipo: medias muy cercanas (Free ≈ 4.19, Paid ≈ 4.27). La diferencia es pequeña y probablemente no significativa sin controlar otras variables (p. ej., `Category`).\n",
    "  - Implicaciones: por el desbalance extremo, conviene usar `is_free` como binaria y, si se modela interacción con `Installs` o `Price`, puede emerger señal. Validar regla `Type=Free ⇒ Price=0`.\n",
    "\n",
    "- Genres Main (primer género)\n",
    "  - Distribución: gran cola larga; `Others` concentra ~48%. Entre Top-12, `Tools`, `Entertainment` y `Education` destacan en frecuencia.\n",
    "  - Rating por género: diferencias pequeñas (medianas ~4.2–4.4), con algunas variaciones en dispersión (p. ej., `Medical` y `Lifestyle` más variables).\n",
    "  - Implicaciones: por la alta cardinalidad y colas largas, mantener Top-K + `Others` en EDA ayuda a la legibilidad. Para modelado, preferir codificación que reduzca dimensionalidad (Top-K dummies, hashing, o target encoding con validación adecuada)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_categorical_compact(df: pd.DataFrame, cat_col: str, target_col: str, top_n: int = 12):\n",
    "    \"\"\"\n",
    "    Versión compacta para variables con muchas categorías:\n",
    "    - Ordena por frecuencia, muestra top_n y agrupa el resto en \"Others\".\n",
    "    - Barras horizontales, pie chart compacto, boxplot y tabla para top_n.\n",
    "    \"\"\"\n",
    "    data = df[[cat_col, target_col]].dropna(subset=[cat_col, target_col]).copy()\n",
    "    if data.empty:\n",
    "        print(f\"Sin datos para {cat_col} y {target_col}\")\n",
    "        return\n",
    "\n",
    "    counts = data[cat_col].value_counts()\n",
    "    top_cats = counts.head(top_n)\n",
    "    others_count = counts.iloc[top_n:].sum()\n",
    "\n",
    "    # Mapeo a top_n + Others\n",
    "    mapping = {c: c for c in top_cats.index}\n",
    "    data['__cat__'] = data[cat_col].where(data[cat_col].isin(top_cats.index), other='Others')\n",
    "\n",
    "    # Recalcular conteos con Others\n",
    "    counts_compact = data['__cat__'].value_counts()\n",
    "    order = list(top_cats.index) + (['Others'] if 'Others' in counts_compact.index else [])\n",
    "\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "    # 1) Barras horizontales (mejor legibilidad)\n",
    "    ax1 = axes[0, 0]\n",
    "    vals = counts_compact.loc[order]\n",
    "    ax1.barh(range(len(vals)), vals.values, color=plt.cm.Set3(range(len(vals))))\n",
    "    ax1.set_yticks(range(len(vals)))\n",
    "    ax1.set_yticklabels(order)\n",
    "    ax1.invert_yaxis()\n",
    "    ax1.set_title(f'Distribución (Top {top_n}) de {cat_col}')\n",
    "    ax1.set_xlabel('Frecuencia')\n",
    "    for i, v in enumerate(vals.values):\n",
    "        ax1.text(v, i, f'  {v} ({v/len(data)*100:.1f}%)', va='center')\n",
    "\n",
    "    # 2) Pie chart compacto\n",
    "    ax2 = axes[0, 1]\n",
    "    ax2.pie(vals.values, labels=order, autopct='%1.1f%%', startangle=140,\n",
    "            colors=plt.cm.Set3(range(len(vals))))\n",
    "    ax2.set_title(f'Proporción (Top {top_n} + Others) de {cat_col}')\n",
    "\n",
    "    # 3) Boxplot del target por categoría (solo top_n)\n",
    "    ax3 = axes[1, 0]\n",
    "    top_mask = data['__cat__'] != 'Others'\n",
    "    data_top = data[top_mask]\n",
    "    data_top.boxplot(column=target_col, by='__cat__', ax=ax3)\n",
    "    ax3.set_title(f'{target_col} por {cat_col} (Top {top_n})')\n",
    "    ax3.set_xlabel(cat_col)\n",
    "    ax3.set_ylabel(target_col)\n",
    "    plt.sca(ax3)\n",
    "    plt.xticks(rotation=30, ha='right')\n",
    "\n",
    "    # 4) Tabla de estadísticas por categoría (solo top_n y Others si existe)\n",
    "    ax4 = axes[1, 1]\n",
    "    ax4.axis('off')\n",
    "    stats_by_cat = data.groupby('__cat__')[target_col].agg(['count', 'mean', 'median', 'std']).loc[order].round(2)\n",
    "    table = ax4.table(cellText=stats_by_cat.reset_index().values,\n",
    "                      colLabels=['Categoría', 'N', 'Media', 'Mediana', 'Desv.Est.'],\n",
    "                      cellLoc='center', loc='center', colWidths=[0.35, 0.12, 0.16, 0.16, 0.16])\n",
    "    table.auto_set_font_size(False)\n",
    "    table.set_fontsize(9)\n",
    "    table.scale(1.05, 1.25)\n",
    "    for i in range(5):\n",
    "        table[(0, i)].set_facecolor('#40E0D0')\n",
    "        table[(0, i)].set_text_props(weight='bold')\n",
    "\n",
    "    plt.suptitle(f'Análisis Categórico Compacto: {cat_col}', fontsize=14, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Ejecutar la versión compacta para las categóricas clave\n",
    "for cat in [c for c in ['Category', 'Content Rating', 'Type', 'Genres Main'] if c in applications_data.columns]:\n",
    "    analyze_categorical_compact(applications_data, cat, 'Rating', top_n=12)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-playstore-z4vSTk52-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
